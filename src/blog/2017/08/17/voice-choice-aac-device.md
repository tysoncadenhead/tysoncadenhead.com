In late 2013, my oldest son was diagnosed with autism. Autism is a spectrum disorder, which means that there are a huge range of abilities and disabilities within it. My son will be 6 this October and he is still completely non-verbal. This is not the case for everyone with autism, but it is the shape of autism that we know. Over the past four years, we have been searching for ways for our son to be able to communicate with us. We've tried several different augmentative and alternative communication devices and iPad apps, but they have all been too complicated to get started on. We needed something simpler. That's when it struck me. I am a programmer. If the product that we need doesn't exist, I can make it. And so began my journey creating Voice Choice.

![Create a new Choice](/images/blog/voicechoice1.png)

The idea was to make Voice Choice as simple and easy to use as possible. Our son doesn't care much for the iPad because he associates it with therapy, so we needed something quick and instantly rewarding that we could work into our day-to-day life.

After some brainstorming, it became obvious that the most rewarding app I could make for our son would be something where we could present him with two or more choices, say "Apple" or "Banana", and he could tap the image and instantly be rewarded by us providing him with the item that he chose.

All of the other communication apps we've encountered have been built around communicating thoughts and complex sentences. We hope to eventually graduate our son to something like that, but Voice Choice is a necessary transitional step that nobody had created.

![Select Choices](/images/blog/voicechoice2.jpeg)

Voice Choice is build with accessibility in mind. The choices are very large and easy to tap. This is intentional because our son has trouble with tasks involving the use of fine-motor skills. We wanted to make sure there would be no obstacles in the way of our son using the app and feeling gratification from it.

![Make a Choice](/images/blog/voicechoice3.jpg)

Many of the AAC applications we've tried have had a built-in library of PECS or PECS-like illustrations. Knowing our son's needs, we realized that it might take a leap to get from drawn illustrations to real-life objects. With many objects or choices, there may be some minor detail that makes it recognizable as the item that it is. While simplifying it to a basic illustration might make sense for a neurotypical child, in our son's case, he seemed to have difficulty associating iconography with reality. Because of that, I built in the ability to take your own photos.

I also wanted to reinforce that auditory side of the choice. We still hope to foster verbal communication with our son and even though he isn't verbal, he still understands a great deal of spoken language. For this, I built in a voice to state the choices and announce the choice that is selected.

Since this is a tech blog, I'll spill the beans and say that this app was built with React Native, Redux, Ramda and Recompose using Firebase as a backend. I've found myself building more and more React Native apps and app integrations lately and it has been a really nice development experience as a JavaScript-heavy programmer dipping my toe into the native world.

VoiceChoice is available as an iPad app in the [App Store](https://itunes.apple.com/us/app/voicechoice-verbal-assistant/id1266540796) for just $9.99. I'm considering offering it as an iPhone and possibly an Android app in the future, but I'm still trying to gauge interest.

If you have a child or know a family with a child who is nonverbal or preverbal, this app could be a game-changer for them!

